{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VEST VA 2017 Governor, Lt Governor, Attorney General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VEST Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Election results from Virginia Department of Elections (https://historical.elections.virginia.gov/)\n",
    "\n",
    "Absentee ballots and provisional votes were reported at the county or city level throughout the state. These were distributed by candidate to precincts based on their share of the precinct-level reported vote.\n",
    "\n",
    "Precinct shapefile primarily from the U.S. Census Bureau's 2020 Redistricting Data Program Phase 2 release. Virginia election reports often include precinct splits that are obsolete or unused in practice. These have been omitted. In cases where voters were incorrectly assigned to the wrong district the de facto precinct split has been included for that election.\n",
    "\n",
    "The following modifications were made to recreate the 2017 precinct boundaries.\n",
    "\n",
    "Albemarle: Merge Cale/Biscuit Run, Free Bridge/Pantops; Add Belfield from 2010 VTD shapefile; Adjust Brownsville/Crozet to match 2010 VTD shapefile  \n",
    "Arlington: Adjust Gunston/Oakridge to match county GIS shapefile  \n",
    "Bedford: Merge New London Academy/Forest Fire Station #2 to reverse 2018 split  \n",
    "Bristol City: Adjust Ward 2/Ward 4 to match description in municipal code  \n",
    "Carroll: Split Oakland A/Oakland D to match county GIS shapefile  \n",
    "Charles City County: Adjust District 1/District 2 boundary to match county code  \n",
    "Covington City: Realign Ward 1, Ward 2, Ward 3 to match city PDF map and municipal code  \n",
    "Culpeper: Adjust East Fairfax/Brandy Station boundary to match county GIS shapefile  \n",
    "Emporia City: Adjust Precincts 1/7, Precincts 2/5 to match municipal code  \n",
    "Essex: Adjust South Precinct/Central Precinct boundary to match county PDF  \n",
    "Fairfax: Adjust Virginia Run/Bull Run to match county GIS shapefile  \n",
    "Fredericksburg City: Adjust District 1/3 boundaries to match municipal code  \n",
    "Galax City: Adjust North/South precinct boundary to match municipal GIS shapefile  \n",
    "Goochland: Adjust Hadensville/Fife boundary to match description in county code  \n",
    "Halifax: Merge South Boston East/West; Adjust Meadville/Republican Grove to match 2011 redistricting PDF map  \n",
    "Hampton City: Add US House District 2 segment of Tyler Precinct to match county PDF  \n",
    "Hanover: Adjust Blunts/Beaverdam boundary to match county PDF  \n",
    "Henrico: Split Glenside/Johnson to match 2010 VTD shapefile  \n",
    "Henry: Adjust 10 precinct boundaries to align VTDs with county GIS shapefile  \n",
    "Madison: Adjust all precincts to align VTDs with county GIS shapefile  \n",
    "Newport News City: Adjust Sanford/Riverview boundary to match county GIS shapefile  \n",
    "Prince William: Adjust Ben Lomond/Mullen, Freedom/Leesylvania to match county GIS shapefile  \n",
    "Pulaski: Adjust Dublin/New River to match precinct assignments on county GIS parcel viewer  \n",
    "Rappahanock: Adjust Sperryville/Washington boundary to match county PDF  \n",
    "Richmond County: Adjust Precincts 2-1/3-1 boundary to match description in county ordinance  \n",
    "Roanoke City: Add Virginia Heights-Norwich; Adjust Forest Park/Eureka Park based on county GIS shapefile and description in municipal ordinance  \n",
    "Roanoke County: Adjust 12 precinct boundaries to match county GIS shapefile  \n",
    "Rockingham: Adjust Bridgewater Precinct to match municipal boundary  \n",
    "Russell: Adjust Daugherty/West Lebanon boundary to match county PDF  \n",
    "Tazewell: Adjust nearly all precinct boundaries to align VTDs with county GIS shapefile  \n",
    "Virginia Beach City: Merge Salem Woods/Rosemont Forest, Sigma/Sandbridge to match 2015 PDF; Adjust Centerville/Colonial to match county GIS shapefile  \n",
    "Williamsburg City: Revise Matoaka/Stryker to match municipal PDF map and municipal code  \n",
    "Wise: Adjust Big Stone Gap/East Stone Gap boundary to match county GIS shapefile  \n",
    "Wythe: Adjust West Wytheville/East Wytheville boundary to match county GIS shapefile  \n",
    "\n",
    "Results are divided across three files. Because precincts can be split across legislative districts, the legislative races are reported with their own geography that divides these split precincts, resulting in shapes that are assigned to exactly one district.  \n",
    "\n",
    "*va_2017 file*\n",
    "G17GOVDNOR - Ralph Northam (Democratic Party)  \n",
    "G17GOVRGIL - Ed Gillespie (Republican Party)  \n",
    "G17GOVLHYR - Cliff Hyra (Libertarian Party)  \n",
    "G17GOVOWRI - Write-in Votes  \n",
    "\n",
    "G17LTGDFAI - Justin Fairfax (Democratic Party)  \n",
    "G17LTGRVOG - Jill Vogel (Republican Party)  \n",
    "G17LTGOWRI - Write-in Votes  \n",
    "\n",
    "G17ATGDHER - Mark Herring (Democratic Party)  \n",
    "G17ATGRADA - John Adams (Republican Party)  \n",
    "G17ATGOWRI - Write-in Votes  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load VEST file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfv = gp.read_file('./raw_from_source/va_2017/va_2017.shp')\n",
    "gdfv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_dict = pd.Series(gdfv['COUNTYFP'].values, index = gdfv['LOCALITY']).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load election results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Governor\n",
    "gov = pd.read_csv('./raw_from_source/Virginia_Elections_Database__2017_Governor_General_Election_including_precincts.csv')\n",
    "#Lt Gov\n",
    "ltg = pd.read_csv('./raw_from_source/Virginia_Elections_Database__2017_Lieutenant_Governor_General_Election_including_precincts.csv')\n",
    "#Attorney General\n",
    "atg = pd.read_csv('./raw_from_source/Virginia_Elections_Database__2017_Attorney_General_General_Election_including_precincts.csv')\n",
    "\n",
    "gov['join_id'] = gov['County/City']+gov['Pct']\n",
    "ltg['join_id']= ltg['County/City']+ltg['Pct']\n",
    "atg['join_id'] = atg['County/City']+atg['Pct']\n",
    "\n",
    "gov_ltg = pd.merge(gov, ltg, on = 'join_id', how = 'outer')\n",
    "df = pd.merge(atg, gov_ltg, on = 'join_id', how = 'outer')\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(value = 0)\n",
    "df = df[(df['County/City'] != 'TOTALS') & (df['join_id'] != 0)]\n",
    "df['LOCALITY'] = df['County/City']\n",
    "#Import county fip number values\n",
    "df['COUNTYFP'] = df['LOCALITY'].map(county_dict)\n",
    "#Change columns to match vest candidate ids\n",
    "df['G17GOVDNOR'] = df['Ralph Shearer Northam'].map(lambda x: str(x).replace(',', '')).astype(str).astype(float).astype(int) \n",
    "df['G17GOVDNOR'] = df['Ralph Shearer Northam'].map(lambda x: str(x).replace(',', '')).astype(str).astype(float).astype(int)\n",
    "df['G17GOVRGIL'] = df['Edward Walter Gillespie'].map(lambda x: str(x).replace(',', '')).astype(str).astype(float).astype(int)\n",
    "df['G17GOVLHYR'] = df['Clifford Daniel Hyra'].map(lambda x: str(x).replace(',', '')).astype(str).astype(float).astype(int)\n",
    "df['G17GOVOWRI'] = df['All Others_x'].map(lambda x: str(x).replace(',', '')).astype(str).astype(float).astype(int)\n",
    "\n",
    "df['G17LTGDFAI'] = df['Justin Edward Fairfax'].map(lambda x: str(x).replace(',', '')).astype(str).astype(float).astype(int)\n",
    "df['G17LTGRVOG'] = df['Jill Holtzman Vogel'].map(lambda x: str(x).replace(',', '')).astype(str).astype(float).astype(int)\n",
    "df['G17LTGOWRI'] = df['All Others_y'].map(lambda x: str(x).replace(',', '')).astype(str).astype(float).astype(int)\n",
    "\n",
    "df['G17ATGDHER'] = df['Mark Rankin Herring'].map(lambda x: str(x).replace(',', '')).astype(str).astype(float).astype(int)\n",
    "df['G17ATGRADA'] = df['John Donley Adams'].map(lambda x: str(x).replace(',', '')).astype(str).astype(float).astype(int)\n",
    "df['G17ATGOWRI'] = df['All Others'].map(lambda x: str(x).replace(',', '')).astype(str).astype(float).astype(int)\n",
    "#drop repeat columns\n",
    "df = df.drop(['County/City_x', 'Ward_x', 'Total Votes Cast_x','County/City_y', 'Ward_y', 'Total Votes Cast_y',\n",
    "             'Ralph Shearer Northam','Edward Walter Gillespie','Clifford Daniel Hyra','All Others_x','Justin Edward Fairfax','Jill Holtzman Vogel','All Others_y',\n",
    "             'Mark Rankin Herring','John Donley Adams','All Others', 'Pct_x', 'Pct_y'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check vote totals - pre absentee reallocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column/race\n",
    "column_list = ['G17GOVDNOR', 'G17GOVRGIL', 'G17GOVLHYR', 'G17GOVOWRI', 'G17LTGDFAI', 'G17LTGRVOG', 'G17LTGOWRI','G17ATGDHER', 'G17ATGRADA', 'G17ATGOWRI']\n",
    "for val in column_list:\n",
    "    vote_dif = df[val].sum()-gdfv[val].sum()\n",
    "    if (vote_dif == 0):\n",
    "        print(val+\": EQUAL\")\n",
    "    else:\n",
    "        print(val+\": DIFFERENCE OF \" + str(vote_dif)+ \" VOTES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#county\n",
    "print(\"Counties with differences printed below:\")\n",
    "diff_counties=[]\n",
    "for i in column_list:\n",
    "    diff = df.groupby(['LOCALITY']).sum()[i]-gdfv.groupby(['LOCALITY']).sum()[i]\n",
    "    for val in diff[diff != 0].index.values.tolist():\n",
    "        if val not in diff_counties:\n",
    "            diff_counties.append(val)\n",
    "    if len(diff[diff != 0]!=0):\n",
    "        print(diff[diff != 0].to_string(header=False))\n",
    "print(\"\")\n",
    "print(\"All other races in all counties are equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absentee reallocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to account for counties split by CDs in absentee reallocation to better match VEST's steps\n",
    "def add_cd_to_county(county_list, precinct, countyfp):\n",
    "    if (countyfp in county_list):\n",
    "        countyfp_cd = countyfp + '-' + precinct[-5:-1]\n",
    "        return countyfp_cd\n",
    "    else:\n",
    "        countyfp_cd = countyfp\n",
    "        return countyfp_cd\n",
    "#Set-up for absentee reallocation\n",
    "cd_abs_prov_prec = df[((df['Pct'].map(lambda x: 'Absentee' in str(x))) &(df['Pct'].map(lambda x: 'CD' in str(x)))) | ((df['Pct'].map(lambda x: 'Provisional' in str(x))) & (df['Pct'].map(lambda x: 'CD' in str(x))))]\n",
    "county_with_cd_nec_list = list(cd_abs_prov_prec['COUNTYFP'])\n",
    "\n",
    "df['countyfp_cd'] = df.apply(lambda row: add_cd_to_county(county_with_cd_nec_list, row['Pct'], row['COUNTYFP']), axis = 1)\n",
    "\n",
    "absentee_and_prov = df[(df['Pct'].map(lambda x: 'Absentee' in str(x))) | (df['Pct'].map(lambda x: 'Provisional' in str(x)))]\n",
    "groupby_absentee_and_prov_tot = absentee_and_prov.groupby(['countyfp_cd']).sum()\n",
    "\n",
    "groupby_county_df_tot = df.groupby(['countyfp_cd']).sum()\n",
    "df_no_absent_or_provisional = df[(df['Pct'].map(lambda x: 'Absentee' not in str(x))) & (df['Pct'].map(lambda x: 'Provisional' not in str(x)))\n",
    "                                & (df['LOCALITY'] != 'TOTALS')]\n",
    "groupby_county_tot_no_absentee = df_no_absent_or_provisional.groupby('countyfp_cd').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_absentee_reallocated = df_no_absent_or_provisional.copy()\n",
    "groupby_absentee_and_prov_tot.reset_index(inplace=True,drop=False)\n",
    "groupby_county_tot_no_absentee.reset_index(inplace=True,drop=False)\n",
    "\n",
    "#Create copys of subset dfs to not modify in case want to check back later\n",
    "to_dole_out_totals = groupby_absentee_and_prov_tot.copy()\n",
    "precinct_specific_totals = groupby_county_tot_no_absentee.copy()\n",
    "\n",
    "## PH CODE for vote allocation\n",
    "\n",
    "#Create some new columns for each of these races to deal with the allocation\n",
    "for race in column_list:\n",
    "    add_var = race+\"_add\"\n",
    "    rem_var = race+\"_rem\"\n",
    "    floor_var = race+\"_floor\"\n",
    "    df_with_absentee_reallocated.loc[:,add_var]=0.0\n",
    "    df_with_absentee_reallocated.loc[:,rem_var]=0.0\n",
    "    df_with_absentee_reallocated.loc[:,floor_var]=0.0\n",
    "\n",
    "#Iterate over the rows\n",
    "#Note this function iterates over the dataframe two times so the rounded vote totals match the totals to allocate\n",
    "for index, row in df_no_absent_or_provisional.iterrows():\n",
    "    for race in column_list:\n",
    "        add_var = race+\"_add\"\n",
    "        rem_var = race+\"_rem\"\n",
    "        floor_var = race+\"_floor\"\n",
    "        #Grab the district\n",
    "        county_id = row[\"countyfp_cd\"]\n",
    "        #Get the denominator for the allocation (the precinct vote totals)\n",
    "        denom = precinct_specific_totals.loc[precinct_specific_totals[\"countyfp_cd\"]==county_id][race]\n",
    "        #Get one of the numerators, how many districtwide votes to allocate\n",
    "        numer = to_dole_out_totals.loc[to_dole_out_totals[\"countyfp_cd\"]==county_id][race]\n",
    "        #Get the vote totals for this race in this precinct\n",
    "        val = df_with_absentee_reallocated.at[index,race]\n",
    "        #Get the vote share, the precincts % of total precinct votes in the district times votes to allocate\n",
    "        if ((float(denom)==0)):\n",
    "            vote_share = 0\n",
    "        else:\n",
    "            vote_share = (float(val)/float(denom))*float(numer)\n",
    "        df_with_absentee_reallocated.at[index,add_var] = vote_share\n",
    "        #Take the decimal remainder of the allocation\n",
    "        df_with_absentee_reallocated.at[index,rem_var] = vote_share%1\n",
    "        #Take the floor of the allocation\n",
    "        df_with_absentee_reallocated.at[index,floor_var] = np.floor(vote_share)\n",
    "\n",
    "#After the first pass through, get the sums of the races by district to assist in the rounding            \n",
    "first_allocation = pd.DataFrame(df_with_absentee_reallocated.groupby([\"countyfp_cd\"]).sum())\n",
    "\n",
    "#Now we want to iterate district by district to work on rounding\n",
    "county_list = list(to_dole_out_totals[\"countyfp_cd\"].unique()) \n",
    "\n",
    "#Iterate over the district\n",
    "for county in county_list:\n",
    "    for race in column_list:\n",
    "        add_var = race+\"_add\"\n",
    "        rem_var = race+\"_rem\"\n",
    "        floor_var = race+\"_floor\"\n",
    "        #County how many votes still need to be allocated (because we took the floor of all the initial allocations)\n",
    "        to_go = int(np.round((int(to_dole_out_totals.loc[to_dole_out_totals[\"countyfp_cd\"]==county][race])-first_allocation.loc[first_allocation.index==county,floor_var])))\n",
    "        #Grab the n precincts with the highest remainders and round these up, where n is the # of votes that still need to be allocated\n",
    "        for index in df_with_absentee_reallocated.loc[df_with_absentee_reallocated[\"countyfp_cd\"]==county][rem_var].nlargest(to_go).index:\n",
    "            df_with_absentee_reallocated.at[index,add_var] = np.ceil(df_with_absentee_reallocated.at[index,add_var])\n",
    "\n",
    "#Iterate over every race again\n",
    "for race in column_list:\n",
    "    add_var = race+\"_add\"\n",
    "    #Round every allocation down to not add fractional votes\n",
    "    df_with_absentee_reallocated.loc[:,add_var]=np.floor(df_with_absentee_reallocated.loc[:,add_var])\n",
    "    df_with_absentee_reallocated.loc[:,race]+=df_with_absentee_reallocated.loc[:,add_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check vote totals - post absentee reallocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column/race total check\n",
    "for val in column_list:\n",
    "    vote_dif = df_with_absentee_reallocated[val].sum()-gdfv[val].sum()\n",
    "    if (vote_dif == 0):\n",
    "        print(val+\": EQUAL - \"+ str(df_with_absentee_reallocated[val].sum()))\n",
    "    else:\n",
    "        print(val+\": DIFFERENCE OF \" + str(vote_dif)+ \" VOTES\")\n",
    "        \n",
    "print(\"Columns with differences printed below:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Differences between RDH/Partner total and VA Dept of Elections totals\n",
    "one = 1409175 - 1408818.0\n",
    "two = 1175731 - 1175732.0\n",
    "three = 27987 - 27987.0\n",
    "four = 1389 - 1528.0\n",
    "five = 1368261 - 1368412.0\n",
    "six = 1224519 - 1224520.0\n",
    "seven = 2446 - 2606.0\n",
    "eight = 1385389 - 1385390.0\n",
    "nine = 1209339 - 1209540.0\n",
    "ten = 2486 - 2614.0\n",
    "\n",
    "print(one, two, three, four, five, six, seven, eight, nine, ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def county_totals_check(partner_df,source_df,column_list,county_col,full_print=False):\n",
    "    print(\"***Countywide Totals Check***\")\n",
    "    print(\"\")\n",
    "    diff_counties=[]\n",
    "    for race in column_list:\n",
    "        diff = partner_df.groupby([county_col]).sum()[race]-source_df.groupby([county_col]).sum()[race]\n",
    "        for val in diff[diff != 0].index.values.tolist():\n",
    "            if val not in diff_counties:\n",
    "                diff_counties.append(val)\n",
    "        if len(diff[diff != 0]!=0):   \n",
    "            print(race + \" contains differences in these counties:\")\n",
    "            for val in diff[diff != 0].index.values.tolist():\n",
    "                county_differences = diff[diff != 0]\n",
    "                print(\"\\t\"+val+\" has a difference of \"+str(county_differences[val])+\" votes\")\n",
    "                print(\"\\t\\tVEST: \"+str(partner_df.groupby([county_col]).sum().loc[val,race])+\" votes\")\n",
    "                print(\"\\t\\tSOURCES: \"+str(source_df.groupby([county_col]).sum().loc[val,race])+\" votes\")\n",
    "            if (full_print):\n",
    "                for val in diff[diff == 0].index.values.tolist():\n",
    "                    county_similarities = diff[diff == 0]\n",
    "                    print(\"\\t\"+val + \": \"+ str(partner_df.groupby([county_col]).sum().loc[val,race])+\" votes\")\n",
    "        else:\n",
    "            print(race + \" is equal across all counties\")\n",
    "            if (full_print):\n",
    "                for val in diff[diff == 0].index.values.tolist():\n",
    "                    county_similarities = diff[diff == 0]\n",
    "                    print(\"\\t\"+val + \": \"+ str(partner_df.groupby([county_col]).sum().loc[val,race])+\" votes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_totals_check(df_with_absentee_reallocated,gdfv,column_list,\"LOCALITY\",False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Identifier to enable merge between election results and vest file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rely on VTDST code from vest file, and subset code from election results precinct column\n",
    "def vtdst_changer(vtdst):\n",
    "    if (vtdst[1:3] == ' -'):\n",
    "        two_lead_zero = '00' + vtdst[:1]\n",
    "        return two_lead_zero\n",
    "    elif (vtdst[1:3] == '- '):\n",
    "        two_lead_zero = '00' + vtdst[:1]\n",
    "        return two_lead_zero\n",
    "    elif (vtdst[-1:] == ' '):\n",
    "        one_lead_zero = '0' + vtdst[:2]\n",
    "        return one_lead_zero\n",
    "    elif (vtdst[-1:] == '-'):\n",
    "        one_lead_zero = '0' + vtdst[:2]\n",
    "        return one_lead_zero\n",
    "    else:\n",
    "        return vtdst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolating 3 digit VTDST code in election results as it appears in the shapefile and vest file, then creating unique id\n",
    "df_with_absentee_reallocated['vtdst'] = df_with_absentee_reallocated.Pct.str.slice(stop = 3)\n",
    "df_with_absentee_reallocated['vtdst'] = df_with_absentee_reallocated['vtdst'].apply(vtdst_changer)\n",
    "df_with_absentee_reallocated['unique_id'] = df_with_absentee_reallocated['COUNTYFP'] + df_with_absentee_reallocated['vtdst']\n",
    "gdfv['unique_id'] = gdfv['COUNTYFP'] + gdfv['VTDST'].str.slice(start = 3)\n",
    "\n",
    "print('id in vest file not in df: ', set(gdfv['unique_id']) - set(df_with_absentee_reallocated['unique_id']))\n",
    "print('id in df not in vest file: ', set(df_with_absentee_reallocated['unique_id']) - set(gdfv['unique_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_in_df = df_with_absentee_reallocated['unique_id'].value_counts()\n",
    "df_double_list = double_in_df[double_in_df > 1].index\n",
    "double_in_vest = gdfv['unique_id'].value_counts()\n",
    "vest_double_list = double_in_vest[double_in_vest > 1].index\n",
    "print('doubled in vest file not doubled in df',set(vest_double_list) - set(df_double_list))\n",
    "print('doubled in df not doubled in vest file', set(df_double_list) - set(vest_double_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of \"unique\" values that are not unique - they are doubled and need to be made unique\n",
    "df_double_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add cd to unique_id to add uniqueness to the doubled ids in vest file and election results df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfv[gdfv['unique_id'].isin(df_double_list)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfv['old_unique_id'] = gdfv['unique_id']\n",
    "df_with_absentee_reallocated['old_unique_id'] = df_with_absentee_reallocated['unique_id']\n",
    "\n",
    "gdfv['cd'] = gdfv['PRECINCT'].str.slice(start=-3, stop=-1)\n",
    "df_with_absentee_reallocated['cd'] = df_with_absentee_reallocated['Pct'].str.slice(start=-3, stop=-1)\n",
    "\n",
    "gdfv['id_w_cd'] = gdfv['unique_id']+'-'+gdfv['cd']\n",
    "df_with_absentee_reallocated['id_w_cd'] = df_with_absentee_reallocated['unique_id']+'-'+df_with_absentee_reallocated['cd']\n",
    "\n",
    "gdfv.loc[gdfv['unique_id'].isin(df_double_list), 'unique_id'] = gdfv.loc[gdfv['unique_id'].isin(df_double_list), 'id_w_cd']\n",
    "df_with_absentee_reallocated.loc[df_with_absentee_reallocated['unique_id'].isin(df_double_list), 'unique_id'] = df_with_absentee_reallocated.loc[df_with_absentee_reallocated['unique_id'].isin(df_double_list), 'id_w_cd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_absentee_reallocated[['old_unique_id', 'unique_id']][df_with_absentee_reallocated['old_unique_id'].isin(df_double_list)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join attempt 1 - election results to vest to check precinct totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_1_df_vest = pd.merge(df_with_absentee_reallocated, gdfv, on = 'unique_id', how = 'outer', indicator = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(join_1_df_vest[\"_merge\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_absentee_reallocated.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See in election results comparison (validation run 1) that the only mismatch > 1 is in Roanoke City - check out and compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_1_df_vest[join_1_df_vest[\"_merge\"]==\"left_only\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_1_df_vest[join_1_df_vest[\"_merge\"]==\"right_only\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_absentee_reallocated[df_with_absentee_reallocated['unique_id'] == '770020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfv[gdfv['unique_id'] == '770019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_absentee_reallocated[df_with_absentee_reallocated['unique_id'] == '770019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfv[gdfv['unique_id'] == '770020']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modifications to create match**\n",
    "\n",
    "Election results df `770019` = gdfv `770020`\n",
    "\n",
    "Election results df `770020` != gdfv `770019` -- why are df `770020` election results so off?\n",
    "\n",
    "Election results df `770018` = gdfv `770019`\n",
    "\n",
    "Election results df `770020` = gdfv `770021`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make modifications based on first join attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix Roanoke City\n",
    "df_with_absentee_reallocated.loc[df_with_absentee_reallocated['old_unique_id']=='770019', 'unique_id'] = '770020'\n",
    "df_with_absentee_reallocated.loc[df_with_absentee_reallocated['old_unique_id']=='770018', 'unique_id'] = '770019'\n",
    "df_with_absentee_reallocated.loc[df_with_absentee_reallocated['old_unique_id']=='770020', 'unique_id'] = '770021'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join attempt 2 - election results to vest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_2_df_vest = pd.merge(df_with_absentee_reallocated, gdfv, on = 'unique_id', how = 'outer', indicator = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(join_2_df_vest[\"_merge\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_2_df_vest[join_2_df_vest[\"_merge\"]==\"right_only\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running validation on Join attempt 2, `770019` still has issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_2_df_vest[join_2_df_vest['unique_id']=='770019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run modification to better match results\n",
    "df_with_absentee_reallocated.loc[df_with_absentee_reallocated['id_w_cd']=='770018-ic', 'unique_id']='770018'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join attempt 3 - election results to vest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_3_df_vest = pd.merge(df_with_absentee_reallocated, gdfv, on = 'unique_id', how = 'outer', indicator = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(join_3_df_vest[\"_merge\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_3_df_vest[join_3_df_vest[\"_merge\"]==\"left_only\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_3_df_vest[join_3_df_vest[\"_merge\"]==\"right_only\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unique id for `770018` listing differently on left and right side, but can see that election results match, and the one precinct - `Fairfax Court` aka `059700` that only appears in VEST's file, not the election results, is a zero vote precinct so does not impact the election results validation. - so, overall great match!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary precinct level election result comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validater_row (df, column_List):\n",
    "    matching_rows = 0\n",
    "    different_rows = 0\n",
    "    diff_list=[]\n",
    "    diff_values = []\n",
    "    max_diff = 0\n",
    "    for j in range(0,len(df.index)):\n",
    "        same = True\n",
    "        for i in column_List:\n",
    "            left_Data = i + \"_x\"\n",
    "            right_Data = i + \"_y\"\n",
    "            diff = abs(df.iloc[j][left_Data]-df.iloc[j][right_Data])\n",
    "            if(diff >0):\n",
    "                if(diff>1): #7/12/21 LF mod to be >1 instead of >0 to print fewer results\n",
    "                    print(i, \"{:.>72}\".format(df.iloc[j][\"unique_id\"]), \"(V)\",\"{:.>5}\".format(int(df.iloc[j][left_Data])),\" (S){:.>5}\".format(int(df.iloc[j][right_Data])),\"(D):{:>5}\".format(int(df.iloc[j][right_Data])-int(df.iloc[j][left_Data])))           \n",
    "                #print(df.iloc[j]['countypct'])\n",
    "                \n",
    "                diff_values.append(abs(diff))\n",
    "                same = False\n",
    "                if(np.isnan(diff)):\n",
    "                    print(\"NaN value at diff is: \", df.iloc[j][\"unique_id\"])\n",
    "                    print(df.iloc[j][left_Data])\n",
    "                    print(df.iloc[j][right_Data])\n",
    "                if (diff>max_diff):\n",
    "                    max_diff = diff\n",
    "                    #print(\"New max diff is: \", str(max_diff))\n",
    "                    #print(df.iloc[j]['cty_pct'])\n",
    "        if(same != True):\n",
    "            different_rows +=1\n",
    "            diff_list.append(df.iloc[j][\"unique_id\"])\n",
    "        else:\n",
    "            matching_rows +=1\n",
    "    print(\"\")\n",
    "    print(\"There are \", len(df.index),\" total rows\")\n",
    "    print(different_rows,\" of these rows have election result differences\")\n",
    "    print(matching_rows,\" of these rows are the same\")\n",
    "    print(\"\")\n",
    "    print(\"The max difference between any one shared column in a row is: \", max_diff)\n",
    "    if(len(diff_values)!=0):\n",
    "        print(\"The average difference is: \", str(sum(diff_values)/len(diff_values)))\n",
    "    count_big_diff = len([i for i in diff_values if i > 10])\n",
    "    print(\"There are \", str(count_big_diff), \"precinct results with a difference greater than 10\")\n",
    "    diff_list.sort()\n",
    "    #print(diff_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validater_row(join_3_df_vest[join_3_df_vest['_merge'] == 'both'].sort_values(\"unique_id\"),column_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precinct Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_fips = []\n",
    "for directory in os.listdir('./raw_from_source/census_shps_by_county_all_unzip/'):\n",
    "    if not directory[0] == '.':\n",
    "        county_fips.append(directory[-5:])\n",
    "        \n",
    "proj = gdfv.crs   \n",
    "\n",
    "county_vtds = []\n",
    "for i in county_fips: #i dont have fips_codes file\n",
    "    ref = './raw_from_source/census_shps_by_county_all_unzip/partnership_shapefiles_19v2_'\n",
    "    vtd_ref = ref + i + '/PVS_19_v2_vtd_' + i + '.shp' \n",
    "    vtd_shp = gp.read_file(vtd_ref)\n",
    "    county_vtds.append(vtd_shp)\n",
    "\n",
    "global shp\n",
    "shp = gp.GeoDataFrame(pd.concat(county_vtds, axis = 0) , crs = proj) \n",
    "\n",
    "shp.plot()\n",
    "gdfv.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp['unique_id'] = shp['COUNTYFP'] + shp['VTDST'].str.slice(start = 3)\n",
    "print('preliminary id in shp not in vest: ', len((set(shp['unique_id']) - set(gdfv['unique_id']))), 'shp length:', shp.shape[0])\n",
    "print('preliminary id in vest not in shp: ', len((set(gdfv['unique_id']) - set(shp['unique_id']))), 'vest length', gdfv.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CD Shapefile - Load in CD info to make splits to match VEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_cd = []\n",
    "\n",
    "for i in county_fips:\n",
    "    ref = './raw_from_source/census_shps_by_county_all_unzip/partnership_shapefiles_19v2_'\n",
    "    cd_ref = ref + i + '/PVS_19_v2_cd_' + i + '.shp' \n",
    "    cd_shp = gp.read_file(cd_ref)\n",
    "    county_cd.append(cd_shp)\n",
    "global cd\n",
    "cd = gp.GeoDataFrame(pd.concat(county_cd, axis = 0) , crs = proj) \n",
    "\n",
    "cd.plot()\n",
    "overlay = gp.overlay(cd, shp, how = 'union', make_valid = True, keep_geom_type = True)\n",
    "overlay.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_w_shp = gp.GeoDataFrame(pd.merge(overlay, shp, on = 'unique_id', how = 'outer'), crs = proj)\n",
    "overlay_w_shp['old_unique_id'] = overlay_w_shp['unique_id']\n",
    "\n",
    "overlay_w_shp['id_w_cd'] = overlay_w_shp['unique_id'] + '- ' +overlay_w_shp['CDFP'].str.lstrip('0')\n",
    "\n",
    "overlay_w_shp.loc[overlay_w_shp['old_unique_id'].isin(df_double_list), 'unique_id'] = overlay_w_shp.loc[overlay_w_shp['unique_id'].isin(df_double_list), 'id_w_cd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overlay_w_shp['unique_id'] = shp['COUNTYFP'] + shp['VTDST'].str.slice(start = 3)\n",
    "print('preliminary id in overlay not in vest: ', len((set(overlay_w_shp['unique_id']) - set(gdfv['unique_id']))), 'overlay length:', shp.shape[0])\n",
    "print('preliminary id in vest not in overlay: ', len((set(gdfv['unique_id']) - set(overlay_w_shp['unique_id']))), 'vest length', gdfv.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_overlay = pd.merge(gdfv, overlay_w_shp, on = 'unique_id', how = 'outer', indicator = True)\n",
    "print(join_overlay[\"_merge\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_only = join_overlay[join_overlay[\"_merge\"]==\"left_only\"]\n",
    "right_only = join_overlay[join_overlay[\"_merge\"]==\"right_only\"]\n",
    "left_only.to_csv(\"./gdfv1_only.csv\")\n",
    "right_only.to_csv(\"./overlay_only.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hand matched in Excel using the csvs and precinct names to determine what needs to be merged versus split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify overlay to match gdfv based on hand matching in Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dict based on Excel hand matching\n",
    "overlay_to_gdf_dict = {\"520041\":\"520004\",\n",
    "\"520042\":\"520004\",\n",
    "\"077011\":\"077401\",\n",
    "\"077012\":\"077401\",\n",
    "\"035401\":\"035405\",\n",
    "\"095041\":\"095104\",\n",
    "\"095042\":\"095104\",\n",
    "\"153112- 10\":\"153112-10\",\n",
    "\"059513- 11\":\"059513-11\",\n",
    "\"153061\":\"153106\",\n",
    "\"153062\":\"153106\",\n",
    "\"685031\":\"685003\",\n",
    "\"685032\":\"685003\",               \n",
    "\"153110- 10\":\"153110-10\",\n",
    "\"153210- 10\":\"153210-10\",\n",
    "\"153210- 11\":\"153210-11\",\n",
    "\"153312- 11\":\"153312-11\",\n",
    "\"153609- 11\":\"153609-11\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply dictionary to improve match rate\n",
    "overlay_w_shp['old_unique_id_w_cd'] = overlay_w_shp['unique_id']\n",
    "overlay_w_shp.loc[overlay_w_shp['old_unique_id_w_cd'].isin(overlay_to_gdf_dict.keys()), 'unique_id'] = overlay_w_shp['old_unique_id_w_cd'].map(overlay_to_gdf_dict)\n",
    "#clean up geometry columns\n",
    "overlay_w_shp['geometry'] = overlay_w_shp['geometry_x']\n",
    "overlay_w_shp.loc[overlay_w_shp['geometry_x'] == None, 'geometry'] = overlay_w_shp.loc[overlay_w_shp['geometry_x'] == None, 'geometry_y']\n",
    "#Dissolve meaning if same id, combine geometries\n",
    "overlay_w_shp = overlay_w_shp.dissolve(by = 'unique_id', as_index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_w_shp.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join shapefile and election results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_df_merge = pd.merge(overlay_w_shp, df_with_absentee_reallocated, on = 'unique_id', how = 'outer', suffixes = ['_x', '_y'], indicator=True)\n",
    "shp_df_gdf = gp.GeoDataFrame(shp_df_merge, geometry = 'geometry')\n",
    "\n",
    "shp_df_gdf = shp_df_gdf.drop(['geometry_x', 'geometry_y'], axis = 1)\n",
    "\n",
    "print(shp_df_merge[\"_merge\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_w_shp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_gdfv_merge = pd.merge(shp_df_gdf, gdfv, on = 'unique_id', how = 'outer', suffixes = ['_x', '_y'])\n",
    "shp_gdfv_merge = shp_gdfv_merge.reset_index()\n",
    "\n",
    "both = shp_gdfv_merge[shp_gdfv_merge[\"_merge\"]==\"both\"]\n",
    "both.reset_index(drop=True,inplace=True)\n",
    "source_geoms = gp.GeoDataFrame(both,geometry=\"geometry_x\",crs=gdfv.crs)\n",
    "vest_geoms = gp.GeoDataFrame(both,geometry=\"geometry_y\",crs=gdfv.crs)\n",
    "source_geoms = source_geoms.to_crs(3857)\n",
    "vest_geoms = vest_geoms.to_crs(3857)\n",
    "source_geoms[\"geometry_x\"]=source_geoms.buffer(0)\n",
    "vest_geoms[\"geometry_y\"]=vest_geoms.buffer(0)\n",
    "vals = source_geoms.geom_almost_equals(vest_geoms,decimal=0)\n",
    "print(vals.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "area_list = []\n",
    "big_diff = pd.DataFrame(columns=[\"area\"])\n",
    "for i in range(0,len(source_geoms)):\n",
    "    diff = source_geoms.iloc[[i]].symmetric_difference(vest_geoms.iloc[[i]])\n",
    "    intersection = source_geoms.iloc[[i]].intersection(vest_geoms.iloc[[i]])\n",
    "    area = float(diff.area/10e6)\n",
    "    area_list.append(area)\n",
    "    #print(\"Area is \" + str(area))\n",
    "\n",
    "    if (area > 1):\n",
    "        count += 1\n",
    "        name = source_geoms.at[i,\"unique_id\"]\n",
    "        big_diff.loc[name]=area\n",
    "        print(str(count)+\") For SOURCE: \" + name + ', VEST: '+ vest_geoms.at[i,\"unique_id\"]+ \" difference in area is \" + str(area))\n",
    "        if (intersection.iloc[0].is_empty):\n",
    "            base = diff.plot(color=\"red\")\n",
    "            source_geoms.iloc[[i]].plot(color=\"orange\",ax=base)\n",
    "            vest_geoms.iloc[[i]].plot(color=\"blue\",ax=base)\n",
    "            base.set_title(name)\n",
    "        else:\n",
    "            base = diff.plot(color=\"red\")\n",
    "            source_geoms.iloc[[i]].plot(color=\"orange\",ax=base)\n",
    "            vest_geoms.iloc[[i]].plot(color=\"blue\",ax=base)\n",
    "            intersection.plot(color=\"green\",ax=base)\n",
    "            base.set_title(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out `unique_id` geometries that look similar above to see if can be combined somehow..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_geoms[(source_geoms['unique_id']=='057301')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_geoms[(source_geoms['unique_id']=='057401')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_geoms[(source_geoms['unique_id']=='075401')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_geoms[(source_geoms['unique_id']=='075402')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_geoms[(source_geoms['unique_id']=='085201')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_geoms[(source_geoms['unique_id']=='085202')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_geoms[(source_geoms['unique_id']=='147101')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_geoms[(source_geoms['unique_id']=='147201')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(area_list)\n",
    "print(df.shape)\n",
    "\n",
    "print(str(len(df[df[0]==0]))+\" precincts w/ a difference of 0 km^2\")\n",
    "print(str(len(df[(df[0]<.1) & (df[0]>0)]))+ \" precincts w/ a difference between 0 and .1 km^2\")\n",
    "print(str(len(df[(df[0]<.5) & (df[0]>=.1)]))+ \" precincts w/ a difference between .1 and .5 km^2\")\n",
    "print(str(len(df[(df[0]<1) & (df[0]>=.5)]))+ \" precincts w/ a difference between .5 and 1 km^2\")\n",
    "print(str(len(df[(df[0]<2) & (df[0]>=1)]))+ \" precincts w/ a difference between 1 and 2 km^2\")\n",
    "print(str(len(df[(df[0]<5) & (df[0]>=2)]))+ \" precincts w/ a difference between 2 and 5 km^2\")\n",
    "print(str(len(df[(df[0]>=5)]))+ \" precincts w/ a difference greater than 5 km^2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
